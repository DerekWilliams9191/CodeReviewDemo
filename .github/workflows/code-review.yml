name: Code Review Training

on:
  pull_request:
    types: [opened, reopened, synchronize]
    branches: [ main ]

# This workflow needs to handle PRs from forks, which have security restrictions
# For PRs from forks, we only do initial testing and analysis here, and upload results as artifacts
# The second workflow will use those artifacts to post comments with appropriate permissions 

jobs:
  test:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: read
    outputs:
      test_passed: ${{ steps.test.outputs.test_passed }}
    
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
          
      - name: Setup .NET
        uses: actions/setup-dotnet@v3
        with:
          dotnet-version: '7.0.x'
          
      - name: Restore dependencies
        run: dotnet restore

      - name: Build
        run: dotnet build --no-restore
        
      - name: Test
        id: test
        run: |
          TEST_EXIT_CODE=0
          dotnet test --no-build --verbosity normal || TEST_EXIT_CODE=$?
          
          echo "test_passed=$([ $TEST_EXIT_CODE -eq 0 ] && echo 'true' || echo 'false')" >> $GITHUB_OUTPUT
          
          # Store test result in file that will be uploaded as an artifact
          echo "TEST_PASSED=$([ $TEST_EXIT_CODE -eq 0 ] && echo 'true' || echo 'false')" > test-results.txt
      
      # Upload the test results as an artifact
      - name: Upload test results
        uses: actions/upload-artifact@v4
        with:
          name: test-results
          path: test-results.txt
      
      # For PRs from forks, we can't comment directly, so we'll upload an artifact for the second workflow
      - name: Create failing test message
        if: steps.test.outputs.test_passed == 'false'
        run: |
          mkdir -p artifacts
          cat > artifacts/review_message.md << EOL
          # ❌ Unit Tests Failed

          The unit tests for this PR are failing. Before we can review the code quality, you need to make the tests pass.

          Please uncomment the necessary code to fix the functionality issues, then we'll review the code for best practices.

          Common issues that might cause test failures:
          - Missing null checks
          - Missing input validation
          - Exception handling is incomplete
          EOL
          
          echo "REQUEST_CHANGES" > artifacts/review_type.txt
          echo "Tests are failing. Please fix the functionality issues first." > artifacts/review_body.txt
          
      - name: Upload failing test message
        if: steps.test.outputs.test_passed == 'false'
        uses: actions/upload-artifact@v4
        with:
          name: pr_message
          path: artifacts/
          retention-days: 1

  code-review:
    runs-on: ubuntu-latest
    needs: test
    if: needs.test.outputs.test_passed == 'true'
    permissions:
      contents: read
    
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
          
      - name: Setup .NET
        uses: actions/setup-dotnet@v3
        with:
          dotnet-version: '7.0.x'
          
      - name: Analyze Code and Create Line-Specific Comments
        id: analyze
        run: |
          # Create artifacts directory
          mkdir -p artifacts
          
          # Get all C# files that were modified in this PR
          FILES=$(git diff --name-only ${{ github.event.pull_request.base.sha }} ${{ github.event.pull_request.head.sha }} | grep '\.cs')

          # Initialize tracking variables
          ISSUES_FOUND=false
          MISSING_NULL_CHECKS=false
          MISSING_VALIDATION=false
          MISSING_DOCUMENTATION=false
          MISSING_EXCEPTION_HANDLING=false
          MISSING_LOGGING=false
          
          # Create an array to store line-specific comments
          echo "[]" > artifacts/line_comments.json
          
          # Loop through each modified C# file
          for FILE in $FILES; do
            echo "Analyzing $FILE..."
            
            # Create a temporary file to store line-specific issues
            LINE_ISSUES_FILE="line_issues_$(basename "$FILE").json"
            echo "[]" > "$LINE_ISSUES_FILE"
            
            # Get the line numbers with null check issues
            NULL_CHECK_LINES=$(grep -n "//\s*if\s*(.*\s*==\s*null)" "$FILE" | cut -d: -f1)
            if [ -n "$NULL_CHECK_LINES" ]; then
              MISSING_NULL_CHECKS=true
              ISSUES_FOUND=true
              
              # For each line with a null check issue, add a comment
              for LINE in $NULL_CHECK_LINES; do
                COMMENT="Missing null check: This appears to be a commented-out null check. For proper error handling, uncomment this code to validate inputs before processing."
                # Add to the line issues JSON
                TMP=$(jq --arg file "$FILE" --arg line "$LINE" --arg body "$COMMENT" \
                  '. += [{"path": $file, "line": $line|tonumber, "body": $body}]' "$LINE_ISSUES_FILE")
                echo "$TMP" > "$LINE_ISSUES_FILE"
              done
            fi
            
            # Check for input validation issues
            VALIDATION_LINES=$(grep -n "//\s*if\s*(!.*\.IsValid" "$FILE" | cut -d: -f1)
            VALIDATION_LINES2=$(grep -n "//\s*validator\.Validate" "$FILE" | cut -d: -f1)
            if [ -n "$VALIDATION_LINES" ] || [ -n "$VALIDATION_LINES2" ]; then
              MISSING_VALIDATION=true
              ISSUES_FOUND=true
              
              # Process all validation lines
              for LINE in $VALIDATION_LINES $VALIDATION_LINES2; do
                COMMENT="Missing input validation: This commented code contains important input validation logic. Uncomment it to ensure proper validation of inputs."
                # Add to the line issues JSON
                TMP=$(jq --arg file "$FILE" --arg line "$LINE" --arg body "$COMMENT" \
                  '. += [{"path": $file, "line": $line|tonumber, "body": $body}]' "$LINE_ISSUES_FILE")
                echo "$TMP" > "$LINE_ISSUES_FILE"
              done
            fi
            
            # Check for documentation issues
            DOC_LINES=$(grep -n "Uncomment for DOCUMENTATION issue" "$FILE" | cut -d: -f1)
            if [ -n "$DOC_LINES" ]; then
              MISSING_DOCUMENTATION=true
              ISSUES_FOUND=true
              
              for LINE in $DOC_LINES; do
                COMMENT="Missing documentation: XML documentation is required for public methods and classes. Uncomment the documentation comments."
                # Add to the line issues JSON
                TMP=$(jq --arg file "$FILE" --arg line "$LINE" --arg body "$COMMENT" \
                  '. += [{"path": $file, "line": $line|tonumber, "body": $body}]' "$LINE_ISSUES_FILE")
                echo "$TMP" > "$LINE_ISSUES_FILE"
              done
            fi
            
            # Find block commented documentation
            DOC_BLOCK_LINES=$(grep -n -A 1 "/\*.*/// <summary>" "$FILE" | head -1 | cut -d: -f1)
            if [ -n "$DOC_BLOCK_LINES" ]; then
              MISSING_DOCUMENTATION=true
              ISSUES_FOUND=true
              
              for LINE in $DOC_BLOCK_LINES; do
                COMMENT="Missing documentation: XML documentation is block-commented. Uncomment this documentation block to properly document the code."
                # Add to the line issues JSON
                TMP=$(jq --arg file "$FILE" --arg line "$LINE" --arg body "$COMMENT" \
                  '. += [{"path": $file, "line": $line|tonumber, "body": $body}]' "$LINE_ISSUES_FILE")
                echo "$TMP" > "$LINE_ISSUES_FILE"
              done
            fi
            
            # Check for exception handling issues
            TRY_LINES=$(grep -n "//\s*try" "$FILE" | cut -d: -f1)
            CATCH_LINES=$(grep -n "//\s*catch" "$FILE" | cut -d: -f1)
            if [ -n "$TRY_LINES" ] || [ -n "$CATCH_LINES" ]; then
              MISSING_EXCEPTION_HANDLING=true
              ISSUES_FOUND=true
              
              # Process try/catch lines
              for LINE in $TRY_LINES; do
                COMMENT="Missing exception handling: Uncomment this try block to properly handle exceptions."
                # Add to the line issues JSON
                TMP=$(jq --arg file "$FILE" --arg line "$LINE" --arg body "$COMMENT" \
                  '. += [{"path": $file, "line": $line|tonumber, "body": $body}]' "$LINE_ISSUES_FILE")
                echo "$TMP" > "$LINE_ISSUES_FILE"
              done
              
              for LINE in $CATCH_LINES; do
                COMMENT="Missing exception handling: Uncomment this catch block to properly handle exceptions."
                # Add to the line issues JSON
                TMP=$(jq --arg file "$FILE" --arg line "$LINE" --arg body "$COMMENT" \
                  '. += [{"path": $file, "line": $line|tonumber, "body": $body}]' "$LINE_ISSUES_FILE")
                echo "$TMP" > "$LINE_ISSUES_FILE"
              done
            fi
            
            # Check for logging issues - FIXED VERSION
            LOGGING_LINES=$(grep -n "Uncomment for LOGGING issue" "$FILE" | cut -d: -f1)
            # Fix: Improved the regex to properly catch commented logging statements
            LOGGER_LINES=$(grep -n "/\*.*_logger\.Log" "$FILE" | cut -d: -f1)
            if [ -n "$LOGGING_LINES" ] || [ -n "$LOGGER_LINES" ]; then
              MISSING_LOGGING=true
              ISSUES_FOUND=true
              
              # Process logging lines
              for LINE in $LOGGING_LINES $LOGGER_LINES; do
                COMMENT="Missing logging: Proper logging is important for production monitoring and debugging. Uncomment these logging statements."
                # Add to the line issues JSON
                TMP=$(jq --arg file "$FILE" --arg line "$LINE" --arg body "$COMMENT" \
                  '. += [{"path": $file, "line": $line|tonumber, "body": $body}]' "$LINE_ISSUES_FILE")
                echo "$TMP" > "$LINE_ISSUES_FILE"
              done
            fi
            
            # STEP 2 section check
            STEP2_LINE=$(grep -n "STEP 2: AFTER TESTS PASS" "$FILE" | cut -d: -f1)
            if [ -n "$STEP2_LINE" ]; then
              # Check for 30 lines after STEP 2 marker for block comments
              STEP2_SECTION=$(tail -n +$STEP2_LINE "$FILE" | head -30)
              if echo "$STEP2_SECTION" | grep -q "/\*"; then
                STEP2_COMMENT_LINE=$((STEP2_LINE + $(echo "$STEP2_SECTION" | grep -n "/\*" | head -1 | cut -d: -f1) - 1))
                MISSING_LOGGING=true
                MISSING_DOCUMENTATION=true
                ISSUES_FOUND=true
                
                COMMENT="Code quality issues in STEP 2: There are block-commented sections in STEP 2 that should be uncommented. These may include logging and documentation."
                # Add to the line issues JSON
                TMP=$(jq --arg file "$FILE" --arg line "$STEP2_COMMENT_LINE" --arg body "$COMMENT" \
                  '. += [{"path": $file, "line": $line|tonumber, "body": $body}]' "$LINE_ISSUES_FILE")
                echo "$TMP" > "$LINE_ISSUES_FILE"
              fi
            fi
            
            # Merge line issues for this file into the main line comments JSON
            jq -s '.[0] + .[1]' artifacts/line_comments.json "$LINE_ISSUES_FILE" > artifacts/temp.json
            mv artifacts/temp.json artifacts/line_comments.json
            rm "$LINE_ISSUES_FILE"
          done
          
          # Save the issues found status to a file
          echo "ISSUES_FOUND=$ISSUES_FOUND" > artifacts/analysis_results.txt
          echo "MISSING_NULL_CHECKS=$MISSING_NULL_CHECKS" >> artifacts/analysis_results.txt
          echo "MISSING_VALIDATION=$MISSING_VALIDATION" >> artifacts/analysis_results.txt
          echo "MISSING_DOCUMENTATION=$MISSING_DOCUMENTATION" >> artifacts/analysis_results.txt
          echo "MISSING_EXCEPTION_HANDLING=$MISSING_EXCEPTION_HANDLING" >> artifacts/analysis_results.txt
          echo "MISSING_LOGGING=$MISSING_LOGGING" >> artifacts/analysis_results.txt
          
          # Create the PR comment content for issue cases
          if [ "$ISSUES_FOUND" == "true" ]; then
            cat > artifacts/review_message.md << EOL
          ## Code Review Results

          🔍 **Code Quality Issues Found:**
          EOL
            
            if [ "$MISSING_NULL_CHECKS" == "true" ]; then
              echo "- ❌ **Missing Null Checks**: The code is missing important null checks. Look for commented lines with null checks and uncomment them." >> artifacts/review_message.md
            fi
            
            if [ "$MISSING_VALIDATION" == "true" ]; then
              echo "- ❌ **Missing Input Validation**: The code doesn't validate inputs before processing them. Find and uncomment the validation code." >> artifacts/review_message.md
            fi
            
            if [ "$MISSING_DOCUMENTATION" == "true" ]; then
              echo "- ❌ **Missing Documentation**: The code lacks proper XML documentation. Uncomment the documentation sections." >> artifacts/review_message.md
            fi
            
            if [ "$MISSING_EXCEPTION_HANDLING" == "true" ]; then
              echo "- ❌ **Missing Exception Handling**: The code doesn't properly handle exceptions. Uncomment the try/catch blocks." >> artifacts/review_message.md
            fi
            
            if [ "$MISSING_LOGGING" == "true" ]; then
              echo "- ❌ **Missing Logging**: The code doesn't include proper logging. Uncomment the logging statements." >> artifacts/review_message.md
            fi
            
            echo -e "\nPlease address these code quality issues by uncommenting the correct code sections and update your PR. **Line-specific comments have been added to the affected code.**" >> artifacts/review_message.md
            
            # Create the PR review body (shorter version that goes with the PR review)
            echo "Code quality issues found. Please see the line-specific comments for details." > artifacts/review_body.txt
            
            # Indicate this should be a "REQUEST_CHANGES" review
            echo "REQUEST_CHANGES" > artifacts/review_type.txt
          else
            # Create the PR comment for success cases
            cat > artifacts/review_message.md << EOL
          ## Code Review Results

          🎉 **Great job!** All tests are passing and code quality standards have been met.
          EOL
            
            # Create the PR review body for success
            echo "All code quality standards have been met. Great job!" > artifacts/review_body.txt
            
            # Indicate this should be an "APPROVE" review
            echo "APPROVE" > artifacts/review_type.txt
          fi

      # Upload the PR review content as an artifact for the second workflow
      - name: Upload PR review artifacts
        uses: actions/upload-artifact@v4
        with:
          name: pr_message
          path: artifacts/
          retention-days: 1
